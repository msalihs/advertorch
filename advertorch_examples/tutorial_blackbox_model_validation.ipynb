{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Robustness using AdverTorch BlackBox Estimators\n",
    "\n",
    "We have previously introduced Advertorch [link to blog post], which is a toolbox for adversarial robustness research. As part of our initiative at RBC, we have been building more tools to validate the robustness of various models and visuals to make it easy for others to understand the results. In this tutorial, we will go through how you can use Advertorch to assess the robustness of your model using the newly added blackbox estimators. These estimators allow you to use the toolbox for any type of model regardless of the deep learning framework used to develop them in the first place. To assess the robustness, we will;\n",
    "- Define what we mean by adversarial robustness\n",
    "- Use AdverTorch to find adversarial examples\n",
    "- Visualize the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Robustness\n",
    "\n",
    "Should there be a link to a paper here or is it safe to provide the definition we normally use? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and Model\n",
    "\n",
    "For this tutorial we will be using a simple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "Accuracy:  0.9298245614035088\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dataset = load_breast_cancer()\n",
    "X, y = dataset.data, dataset.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print(len(X_train[0]))\n",
    "print(\"Accuracy: \", accuracy_score(model.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a BlackBox Relaxation\n",
    "from advertorch.attacks.blackbox import NESWrapper\n",
    "import torch.nn as nn\n",
    "\n",
    "class LambdaLayer(nn.Module):\n",
    "    def __init__(self, lambd):\n",
    "        super(LambdaLayer, self).__init__()\n",
    "        self.lambd = lambd\n",
    "    def forward(self, x):\n",
    "        return self.lambd(x)\n",
    "\n",
    "# Ask Giuseppe\n",
    "activation = LambdaLayer(lambda x: x)\n",
    "pred_fcn = NESWrapper(func=model.predict_proba,  nb_samples=100)\n",
    "bb_estimator = nn.Sequential(pred_fcn, activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobustRegression:\n",
    "    \"\"\"General statement of robustness.\"\"\"\n",
    "\n",
    "    def __init__(self, neighbourhood, model):\n",
    "        super().__init__(neighbourhood, model)\n",
    "\n",
    "    @property\n",
    "    def task(self):\n",
    "        return \"regression\"\n",
    "\n",
    "    def pred(self, x):\n",
    "        with torch.no_grad():\n",
    "            y = self.model.predict(x)\n",
    "        return y\n",
    "\n",
    "    def eval_input(self, X, Xprime, epsilon):\n",
    "        return self.neighbourhood(Xprime, X) <= epsilon\n",
    "\n",
    "    def eval_output(self, Y, Yprime, delta):\n",
    "        return abs(Y - Yprime) > delta\n",
    "\n",
    "    def eval_counterexample(self, X, Xprime, epsilon, delta):\n",
    "        valid_input = self.eval_input(X, Xprime, epsilon)\n",
    "        Y, Yprime = self.pred(X), self.pred(Xprime)\n",
    "        invalid_output = self.eval_output(Y, Yprime, delta)\n",
    "\n",
    "        return valid_input & invalid_output\n",
    "\n",
    "class MultiLabelMixin:\n",
    "    \"\"\"Mixin for multi-class classifiers.\"\"\"\n",
    "\n",
    "    @property\n",
    "    def task(self):\n",
    "        return \"classification\"\n",
    "\n",
    "    def pred(self, x):\n",
    "        with torch.no_grad():\n",
    "            y = self.model.predict(x).argmax(-1)\n",
    "        return y\n",
    "\n",
    "    def eval_output(self, Y, Yprime, delta):\n",
    "        return Y != Yprime\n",
    "        \n",
    "class RobustClassification(MultiLabelMixin, RobustRegression):\n",
    "    \"\"\"For all inputs in a given neighbourhood, check if the model predicts the\n",
    "    same class (according to argmax)\"\"\"\n",
    "\n",
    "    def __init__(self, neighbourhood, model):\n",
    "        super().__init__(neighbourhood=neighbourhood, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Tuple, List, Dict\n",
    "from advertorch.utils import clamp as batch_clamp\n",
    "\n",
    "def parse_config(config: List[Dict]) -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"Extract feature information from a given config.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary of torch tensors.\n",
    "    \"\"\"\n",
    "    n_dim = len(config)\n",
    "\n",
    "    mins = torch.zeros(n_dim)\n",
    "    maxs = torch.zeros(n_dim)\n",
    "    scales = torch.ones(n_dim)\n",
    "    intmask = torch.zeros(n_dim)\n",
    "    ignore = torch.zeros(n_dim)\n",
    "    for i, feature in enumerate(config):\n",
    "        if not feature[\"ignore\"]:\n",
    "            l, u = feature[\"ranges\"][0]\n",
    "            mins[i] = l\n",
    "            maxs[i] = u\n",
    "            scales[i] = feature[\"scales\"][0]\n",
    "\n",
    "        intmask[i] = (\n",
    "            feature[\"Feature_type\"] == \"BIN\"  # noqa: BLK100\n",
    "            or feature[\"Feature_type\"] == \"INT\"\n",
    "        )\n",
    "        ignore[i] = feature[\"ignore\"]\n",
    "\n",
    "    return {\n",
    "        \"mins\": mins,\n",
    "        \"maxs\": maxs,\n",
    "        \"scales\": scales,\n",
    "        \"intmask\": intmask.bool(),\n",
    "        \"ignore\": ignore.bool(),\n",
    "    }\n",
    "\n",
    "class LinfNeighbourhood(nn.Module):\n",
    "    \"\"\"A neighbourhood defined by a Linf-norm constraint.\n",
    "\n",
    "    Args:\n",
    "        pert_mode: Set to 'add' for arithmetic perturbations.\n",
    "            Set to 'ratio' for logarithmic perturbations.\n",
    "\n",
    "        buff: stability buffer for pert_mode ratio\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pert_mode: str = \"add\", buff: float = 1e-9):\n",
    "        nn.Module.__init__(self)\n",
    "        if pert_mode not in {\"add\", \"ratio\"}:\n",
    "            raise ValueError(\n",
    "                \"pert_mode '{}' is not currently supported\".format(pert_mode)\n",
    "            )\n",
    "        self.pert_mode = pert_mode\n",
    "        self.buff = buff\n",
    "\n",
    "    def __call__(\n",
    "        self, x1: torch.FloatTensor, x2: torch.FloatTensor\n",
    "    ) -> torch.FloatTensor:\n",
    "        \"\"\"The Linf metric, applied according to pert_mode.\n",
    "\n",
    "        Args:\n",
    "            x1: Array of inputs.  Shape [n_batch, n_feature]\n",
    "\n",
    "            x2: Array of inputs.  For pert_mode ratio, this is used to\n",
    "                normalize the distance.  Shape [n_batch, n_feature]\n",
    "\n",
    "        Returns:\n",
    "            Distance between the rows of x1 and x2.  Shape [n_batch]\n",
    "        \"\"\"\n",
    "        z1, z2 = self.transform(x1), self.transform(x2)\n",
    "\n",
    "        if self.pert_mode == \"add\":\n",
    "            return (abs(z1 - z2)).max(-1)[0]\n",
    "        elif self.pert_mode == \"ratio\":\n",
    "            # Note: the sign function is used to shift values away from zero,\n",
    "            # which will depend on sign\n",
    "            return abs((z1 - z2) / (z2 + self.buff * sign(z2))).max(-1)[0]\n",
    "\n",
    "    def bounds(\n",
    "        self, x: torch.FloatTensor, eps: torch.FloatTensor\n",
    "    ) -> Tuple[torch.FloatTensor, torch.FloatTensor]:\n",
    "        \"\"\"Upper and lower bounds for the epsilon ball (which has the form of a\n",
    "        square).\n",
    "\n",
    "        Args:\n",
    "            x: Array of inputs.  Shape [n_batch, n_feature]\n",
    "\n",
    "            eps: Value of epsilon.  Shape [n_batch]\n",
    "\n",
    "        Returns:\n",
    "            (bmin, bmax): Tuple of lower and upper bounds.\n",
    "                Shape [n_batch, n_feature]\n",
    "        \"\"\"\n",
    "        if self.pert_mode == \"add\":\n",
    "            # The epsilon ball is defined via small perturbations\n",
    "            # to the original value\n",
    "            bmin, bmax = x - eps[:, None], x + eps[:, None]\n",
    "        elif self.pert_mode == \"ratio\":\n",
    "            # The epsilon ball is defined as a percentage fluctuation of the\n",
    "            # original value\n",
    "            rel_eps = abs(x * eps[:, None])\n",
    "            bmin, bmax = x - rel_eps, x + rel_eps\n",
    "\n",
    "        return bmin, bmax\n",
    "\n",
    "    def project(\n",
    "        self,  # noqa: BLK100\n",
    "        x: torch.FloatTensor,\n",
    "        bounds: Tuple[torch.FloatTensor, torch.FloatTensor],\n",
    "    ) -> torch.FloatTensor:\n",
    "        \"\"\"Clamp a given point within the bounds.\n",
    "\n",
    "        Args:\n",
    "            x: Array of inputs.  Shape [n_batch, n_feature]\n",
    "\n",
    "            bounds: Tuple of (bmin, bmax).  These are the upper and lower\n",
    "                bounds of an epsilon ball.\n",
    "\n",
    "        Return:\n",
    "            The points in x clipped to the range defined by bounds.\n",
    "                Shape [n_batch, n_feature]\n",
    "        \"\"\"\n",
    "        bmin, bmax = bounds\n",
    "        return batch_clamp(x, bmin, bmax)\n",
    "\n",
    "class ScaledLinfNeighbourhood(LinfNeighbourhood):\n",
    "    \"\"\"A neighbourhood defined by a scaled Linf-norm constraint.\n",
    "\n",
    "    Args:\n",
    "        config: list of dicts containing all information about the features\n",
    "\n",
    "        pert_mode: Set to 'add' for arithmetic perturbations.\n",
    "            Set to 'ratio' for logarithmic perturbations.\n",
    "\n",
    "        buff: stability buffer for pert_mode ratio\n",
    "\n",
    "    Attributes:\n",
    "        mins (torch.FloatTensor): Absolute lower bound on the inputs\n",
    "\n",
    "        maxs (torch.FloatTensor): Absolute upper bound on the inputs\n",
    "\n",
    "        scales (torch.FloatTensor): Scale used to normalize the inputs\n",
    "\n",
    "        intmask (torch.BoolTensor): Indicates whether a given feature is an\n",
    "            integer\n",
    "\n",
    "        ignore (torch.BoolTensor): Indicates whether a given dimension should\n",
    "            be kept fixed\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(  # noqa: BLK100\n",
    "        self, config: List[Dict], pert_mode: str = \"add\", buff: float = 1e-9\n",
    "    ):\n",
    "        super().__init__(pert_mode=pert_mode, buff=buff)\n",
    "\n",
    "        self.set_scales(config)\n",
    "\n",
    "    def set_scales(self, config):\n",
    "        for name, buff in parse_config(config).items():\n",
    "            self.register_buffer(name, buff)\n",
    "\n",
    "    def bounds(\n",
    "        self, x: torch.FloatTensor, eps: torch.FloatTensor\n",
    "    ):\n",
    "        \"\"\"Upper and lower bounds for the epsilon ball (which has the form of a\n",
    "        rectangle).\n",
    "\n",
    "        Args:\n",
    "            x: Array of inputs.  Shape [n_batch, n_feature]\n",
    "\n",
    "            eps: Value of epsilon.  Shape [n_batch]\n",
    "\n",
    "        Returns:\n",
    "            (bmin, bmax): Tuple of lower and upper bounds.\n",
    "                Shape [n_batch, n_feature]\n",
    "        \"\"\"\n",
    "        # Use a conditional mask to enforce validity of the generated\n",
    "        # counterexamples.  Features that are outside of the valid range are\n",
    "        # masked, and thus not perturbed\n",
    "        outlier_mask = (x < self.mins) | (x > self.maxs)\n",
    "        mask = outlier_mask | self.ignore\n",
    "\n",
    "        if self.pert_mode == \"add\":\n",
    "            # The epsilon ball is defined via small perturbations to the\n",
    "            # original value, where small is defined by the overall\n",
    "            # range of that value\n",
    "            eps_max = torch.min(x + eps[:, None] * self.scales, self.maxs)\n",
    "            eps_min = torch.max(x - eps[:, None] * self.scales, self.mins)\n",
    "        elif self.pert_mode == \"ratio\":\n",
    "            # The epsilon ball is defined as a percentage fluctuation of the\n",
    "            # original value\n",
    "            rel_eps = abs(x * eps[:, None])\n",
    "\n",
    "            eps_max = torch.min(x + rel_eps, self.maxs)\n",
    "            eps_min = torch.max(x - rel_eps, self.mins)\n",
    "\n",
    "        # We need to use the 1e-9 buffer to ensure the correct traversals\n",
    "        # through the trees.  More specifically, adding 1e-9 will ensure bmin\n",
    "        # lies above eps_min.\n",
    "        # This also ensures the masked features will be normalized correctly\n",
    "        # when distances are computed\n",
    "        bmin = mask * x + ~mask * eps_min - self.buff\n",
    "        bmax = mask * x + ~mask * eps_max + self.buff\n",
    "\n",
    "        # Sanity check\n",
    "        assert torch.all(bmin <= bmax)\n",
    "\n",
    "        return bmin, bmax\n",
    "\n",
    "    def transform(self, x: torch.FloatTensor) -> torch.FloatTensor:\n",
    "        \"\"\"Use the mins and scales to normalize the inputs into the range.\n",
    "\n",
    "        [0,1]\n",
    "        \"\"\"\n",
    "        # TODO:\n",
    "        # This transform will not adjust \"ignored\" variables\n",
    "        # Ex if a feature is supposed to be ignored, and has value 100\n",
    "        # It will have value 100 after transform is called\n",
    "        # Does this introduce any problems? Ex with distance calculation?\n",
    "        return (x - self.mins) / self.scales\n",
    "\n",
    "    def inverse_transform(self, x: torch.FloatTensor) -> torch.FloatTensor:\n",
    "        \"\"\"Use the mins and scales to take the inputs from the range [0,1] to\n",
    "        their raw values.\"\"\"\n",
    "        return x * self.scales + self.mins\n",
    "\n",
    "    def project(\n",
    "        self,  # noqa: BLK100\n",
    "        x: torch.FloatTensor,\n",
    "        bounds,\n",
    "    ) -> torch.FloatTensor:\n",
    "        \"\"\"Clamp a given point within the bounds.\n",
    "\n",
    "        Args:\n",
    "            x: Array of inputs.  Shape [n_batch, n_feature]\n",
    "\n",
    "            bounds: Tuple of (bmin, bmax).  These are the upper and lower\n",
    "                bounds of an epsilon ball.\n",
    "\n",
    "        Return:\n",
    "            The points in x clipped to the range defined by bounds.\n",
    "                Shape [n_batch, n_feature]\n",
    "        \"\"\"\n",
    "        # Clamp to Linf Ball\n",
    "        x = super().project(x, bounds)\n",
    "\n",
    "        # Fix integers\n",
    "        bmin, bmax = bounds\n",
    "        rounded = box_round(x, bmin, bmax)\n",
    "        x = torch.where(self.intmask.bool(), rounded, x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52d1824760583630568b3224a7b4b8173d217e641da449cb1eb4bce95f7222a0"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('advertorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
